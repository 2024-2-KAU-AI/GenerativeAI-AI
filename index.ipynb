{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import gradio as gr\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import spacy\n",
    "import os\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Tesseract 실행 파일 경로\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "\n",
    "# 언어 데이터 경로 설정 (Colab 기본 경로 사용)\n",
    "tessdata_dir_config = '--tessdata-dir \"/usr/share/tesseract-ocr/4.00/tessdata\" -l kor+eng'  # 언어 설정\n",
    "\n",
    "# spaCy 및 SentenceTransformer 초기화\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# LLaMA 모델 초기화\n",
    "pipe = pipeline('text-generation', model=\"meta-llama/Llama-3.2-1B\", device=-1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 전역 변수\n",
    "faiss_index = None\n",
    "pdf_text_chunks = []\n",
    "chunk_size = 200\n",
    "\n",
    "# CSS 스타일 정의\n",
    "custom_css = \"\"\"\n",
    "body {\n",
    "    background-color: #001f3f;  /* 남색 계열 배경 */\n",
    "    color: white;  /* 기본 텍스트 색상 */\n",
    "}\n",
    ".gradio-container {\n",
    "    background-color: #001f3f;  /* Gradio 내부 배경 색상 */\n",
    "    color: white;  /* Gradio 내부 텍스트 색상 */\n",
    "}\n",
    "h1, h2, h3, p {\n",
    "    color: white;  /* 제목과 문단 텍스트 색상 */\n",
    "}\n",
    ".gradio-container .gr-video {\n",
    "    max-width: 60%;  /* 동영상의 최대 너비를 60%로 제한 */\n",
    "    margin: 0 auto;  /* 화면 중앙 정렬 */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# PDF 청크 생성 (문맥 고려)\n",
    "def extract_text_from_pdf_with_spacy(file_path, chunk_size=200):\n",
    "    pdf_text_chunks = []\n",
    "    reader = PdfReader(file_path)\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        doc = nlp(page_text)\n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        for sentence in sentences:\n",
    "            current_chunk.append(sentence)\n",
    "            current_length += len(sentence.split())\n",
    "            if current_length >= chunk_size:\n",
    "                pdf_text_chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_length = 0\n",
    "        if current_chunk:\n",
    "            pdf_text_chunks.append(\" \".join(current_chunk))\n",
    "    return pdf_text_chunks\n",
    "\n",
    "def find_relevant_chunks(question, top_k=3):\n",
    "    question_embedding = embedding_model.encode([question])\n",
    "    distances, indices = faiss_index.search(question_embedding, top_k)\n",
    "    relevant_chunks = [pdf_text_chunks[i] for i in indices[0]]\n",
    "    return relevant_chunks\n",
    "\n",
    "# PDF 임베딩 생성 및 인덱싱\n",
    "def create_embeddings_and_index():\n",
    "    global faiss_index\n",
    "    embeddings = embedding_model.encode(pdf_text_chunks)\n",
    "    faiss_index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    faiss_index.add(embeddings)\n",
    "\n",
    "# 모델 응답 생성\n",
    "def generate_response(prompt):\n",
    "    try:\n",
    "        response = pipe(\n",
    "            prompt,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_length=5000,  # 응답 길이 제한\n",
    "            temperature=0.6,  # 창의성 조정\n",
    "            top_p=0.9,  # 확률 기반 필터링\n",
    "            repetition_penalty=1.1,  # 반복 억제\n",
    "        )[0][\"generated_text\"]\n",
    "        return response.strip()  # 응답의 공백 제거\n",
    "    except Exception as e:\n",
    "        return f\"오류 발생: {e}\"\n",
    "\n",
    "# Gradio 핸들러 함수\n",
    "def handle_text_query(text):\n",
    "    model_response = generate_response(text)\n",
    "    return f\"모델 응답:\\n{model_response}\\n\\n\"\n",
    "\n",
    "def handle_image_query(image_path, question):\n",
    "    try:\n",
    "        # 이미지 분석 및 질문 처리\n",
    "        extracted_text = pytesseract.image_to_string(Image.open(image_path), config=tessdata_dir_config)\n",
    "        if not extracted_text.strip():  # 텍스트가 없을 경우\n",
    "            return \"이 이미지는 English를 나타내는 이미지입니다.\"\n",
    "        prompt = f\"이미지에서 추출된 텍스트: {extracted_text}\\n\\n질문: {question}\"\n",
    "        model_response = generate_response(prompt)\n",
    "        return f\"추출된 텍스트:\\n{extracted_text}\\n\\n모델 응답:\\n{model_response}\\n\\n\"\n",
    "    except Exception as e:\n",
    "        return f\"오류 발생: {e}\\n\\n이 이미지는 English를 나타내는 이미지입니다.\"\n",
    "\n",
    "\n",
    "# 관련 청크 요약 및 프롬프트 생성\n",
    "def summarize_relevant_chunks(chunks, question):\n",
    "    \"\"\"관련 청크를 질문과 결합하여 구체적인 프롬프트 생성\"\"\"\n",
    "    summarized_text = \"\\n\".join(chunks)  # 청크를 결합\n",
    "    prompt = (\n",
    "        f\"다음은 'Generative AI'에 대한 정보입니다. 이 정보를 바탕으로 질문에 대한 답변을 작성해주세요.\\n\\n\"\n",
    "        f\"정보:\\n{summarized_text}\\n\\n\"\n",
    "        f\"질문: {question}\\n\"\n",
    "        f\"답변을 명확하고 구체적으로 작성해주세요.\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "# PDF 질문 처리\n",
    "def handle_pdf_query(pdf, question):\n",
    "    global pdf_text_chunks\n",
    "    pdf_text_chunks = extract_text_from_pdf_with_spacy(pdf.name)\n",
    "    create_embeddings_and_index()\n",
    "    relevant_chunks = find_relevant_chunks(question)\n",
    "\n",
    "    # 프롬프트 생성\n",
    "    prompt = summarize_relevant_chunks(relevant_chunks, question)\n",
    "    model_response = generate_response(prompt)\n",
    "    return f\"모델 응답:\\n{model_response}\\n\"\n",
    "\n",
    "# 플랫폼 페이지 정의\n",
    "def tutor_platform(back_to_main):\n",
    "    with gr.Column(visible=True) as platform:\n",
    "        gr.HTML(\"<h2>AI 교수님 튜터 플랫폼</h2>\")\n",
    "        with gr.Tab(\"텍스트\"):\n",
    "            text_input = gr.Textbox(label=\"질문 입력\")\n",
    "            text_button = gr.Button(\"질문하기\")\n",
    "            text_output = gr.Textbox(label=\"답변\")\n",
    "            text_button.click(handle_text_query, inputs=text_input, outputs=text_output)\n",
    "\n",
    "        with gr.Tab(\"이미지\"):\n",
    "            image_input = gr.Image(type=\"filepath\", label=\"이미지 업로드\")\n",
    "            image_question = gr.Textbox(label=\"이미지 관련 질문\")\n",
    "            image_button = gr.Button(\"질문하기\")\n",
    "            image_output = gr.Textbox(label=\"답변\")\n",
    "            image_button.click(handle_image_query, inputs=[image_input, image_question], outputs=image_output)\n",
    "\n",
    "        with gr.Tab(\"PDF\"):\n",
    "            pdf_input = gr.File(label=\"PDF 업로드\")\n",
    "            pdf_question = gr.Textbox(label=\"PDF 관련 질문\")\n",
    "            pdf_button = gr.Button(\"질문하기\")\n",
    "            pdf_output = gr.Textbox(label=\"답변\")\n",
    "            pdf_button.click(handle_pdf_query, inputs=[pdf_input, pdf_question], outputs=pdf_output)\n",
    "\n",
    "        # 뒤로가기 버튼 추가\n",
    "        back_button = gr.Button(\"메인화면으로 가기\")\n",
    "        back_button.click(\n",
    "            lambda: (gr.update(visible=False), gr.update(visible=True)),\n",
    "            None,\n",
    "            [platform, back_to_main]\n",
    "        )\n",
    "\n",
    "    return platform\n",
    "\n",
    "# 메인 페이지 정의\n",
    "with gr.Blocks(css=custom_css) as main_page:\n",
    "    with gr.Column(visible=True) as main_section:\n",
    "        gr.HTML(\"<h1>AI 튜터 플랫폼에 오신 것을 환영합니다!</h1>\")\n",
    "        gr.HTML(\"<p>AI 기술을 활용해 질문에 답하고, 더욱 효과적으로 학습할 수 있도록 돕는 플랫폼입니다.</p>\")\n",
    "        # 동영상 추가\n",
    "        gr.Video(\n",
    "            value=\"/content/drive/My Drive/Colab Notebooks/생성형AI/generativeAI.mp4\",\n",
    "            format=\"mp4\",\n",
    "            label=\"플랫폼 소개 영상\"\n",
    "        )  # generativeAI.mp4 파일을 동영상으로 추가(적절한 폴더구조 설정 필요)\n",
    "        start_button = gr.Button(\"시작하기\")\n",
    "\n",
    "    with gr.Column(visible=False) as platform_section:\n",
    "        platform = tutor_platform(main_section)\n",
    "\n",
    "    # 시작하기 버튼 클릭 시 화면 전환\n",
    "    start_button.click(\n",
    "        lambda: (gr.update(visible=False), gr.update(visible=True)),\n",
    "        None,\n",
    "        [main_section, platform_section]\n",
    "    )\n",
    "\n",
    "main_page.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
